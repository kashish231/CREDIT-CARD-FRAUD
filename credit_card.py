# -*- coding: utf-8 -*-
"""credit card.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NdyAeMV5rpqUJf7_DTXLWTxPy9RJPRkv

credit card project

Importing the Dependencies
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# loading the dataset to a pandas dataframe
credit_card_data = pd.read_csv('/content/credit card.csv')

# first 5 rows of the data set
credit_card_data.head()

credit_card_data.tail()

#dataset information given by info() function
credit_card_data.info()

# another method for checking missing values in dataset
credit_card_data.isnull().sum()

# distribution of ligit transection & fradulent transection
credit_card_data['Class'].value_counts()



"""this dataset is highly unbalanced as seen only 49 fraudlent transections as comapare to ligit transections

0 -->normal tran
1 --> fraud

"""

# seperating the data for analysis
legit = credit_card_data[credit_card_data.Class==0]
fraud = credit_card_data[credit_card_data.Class==1]

print(legit.shape)
print(fraud.shape)

#statistical measures of the data
legit.Amount.describe()

fraud.Amount.describe()

# compare the values for both transections
credit_card_data.groupby('Class').mean()

"""Under-Sampling

Build a sample dataset containing similar distribution of normal transections and fraudlent transections

number of fraud transections = 49
"""

legit_sample=legit.sample(n=49)

"""concatenating two dataframes """

new_dataset=pd.concat([legit_sample,fraud],axis=0)

new_dataset.head()

new_dataset.tail()

new_dataset['Class'].value_counts()

new_dataset.groupby('Class').mean()

"""splitting the data into features and targets"""

X = new_dataset.drop(columns='Class',axis=1)
Y = new_dataset['Class']

print(X)

print(Y)

"""split the data into training data and teesting data"""

X_train,X_test,Y_train,Y_test = train_test_split(X,Y, test_size=0.2,stratify=Y,random_state=2)

print(X.shape,X_train.shape,X_test.shape)

"""model training
Logistic Regression
"""

model = LogisticRegression()

#training the LogisticRegression model with Training data
model.fit(X_train,Y_train)

"""model evaluation

accuracy score
"""

# accuracy on training data
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction,Y_train)

print('Accuracy on training data : ',training_data_accuracy)

# accuracy on test data
X_test_prediction = model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction,Y_test)

print('Accuracy on testing data : ',test_data_accuracy)

